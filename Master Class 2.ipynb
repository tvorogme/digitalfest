{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DeepTraffic](https://selfdrivingcars.mit.edu/deeptrafficjs/)\n",
    "\n",
    "### [Школа GoTo](https://goto.msk.ru)\n",
    "[Емельяненко Дмитрия](https://github.com/TIXFeniks) <br>\n",
    "[Творожков Андрей](https://tvorog.me)\n",
    "\n",
    "DeepTraffic - это симуляция типично нагруженной дороги. Ваша задача разработать нейронную сеть, которая поможет ускорить трафик на загруженных дорогах.\n",
    "\n",
    "![](https://selfdrivingcars.mit.edu/wordpress/wp-content/uploads/2017/01/Screen-Shot-2017-01-03-at-16.02.05-1024x640.png)\n",
    "\n",
    "Ваша нейронная сеть получает контроль над машиной (обозначена красным цветом) и должна обчиться управлять ей максимально эффективно, чтобы ехать как можно быстрее. Машина уже снабжена системой безопасности, поэтому вы можете не заботиться о столкновениях с другими машинами. Сеть может влиять только на изменение скорости и изменение линий. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разберём стандартный код\n",
    "\n",
    "Есть 3 параметра ответственные за количество клеток передаваемых \n",
    "\n",
    "```\n",
    "lanesSide = 0; // Количество лийи вокруг *радиус*\n",
    "patchesAhead = 1; // Количество клеток впереди\n",
    "patchesBehind = 0; // Количество клеток позади\n",
    "```\n",
    "\n",
    "Вот несколько примеров изменений этих параметров:\n",
    "\n",
    "![](./screens/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Идём дальше\n",
    "<br><br>\n",
    "```\n",
    "// Количество итераций при нажатии кнопки начать обучение\n",
    "trainIterations = 10000; \n",
    "\n",
    "// (Количество линий * 2 (справа и слева) + 1 (по середине)) * (количество клеток впереди + количество клето позади)\n",
    "var num_inputs = (lanesSide * 2 + 1) * (patchesAhead + patchesBehind);\n",
    "\n",
    "// Бездействовать = 0;\n",
    "// Ускорится = 1;\n",
    "// Замедлиться = 2;\n",
    "// Повернуть налево = 3;\n",
    "// Повернуть направо = 4;\n",
    "\n",
    "// Количество действи\n",
    "var num_actions = 5;\n",
    "\n",
    "// Количество раз которое мы запоминаем\n",
    "var temporal_window = 3;\n",
    "\n",
    "// Количество нейронов на вход\n",
    "var network_size = num_inputs * temporal_window + num_actions * temporal_window + num_inputs;\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "# Нейронная сеть!\n",
    "![](https://uccexpress.ie/wp-content/uploads/2017/09/6360498178139720611073070814_Rick-and-Morty.jpg)\n",
    "<br><br>\n",
    "\n",
    "```\n",
    "// Массив со слоями нейронной сети\n",
    "var layer_defs = [];\n",
    "\n",
    "// Входной слой\n",
    "layer_defs.push({\n",
    "    type: 'input',\n",
    "    out_sx: 1,\n",
    "    out_sy: 1,\n",
    "    out_depth: network_size\n",
    "});\n",
    "\n",
    "// Полносвязный слой\n",
    "layer_defs.push({\n",
    "    type: 'fc',\n",
    "    num_neurons: 1,\n",
    "    activation: 'relu'\n",
    "});\n",
    "\n",
    "// Выходной слой, который предсказывает вероятности \n",
    "layer_defs.push({\n",
    "    type: 'regression',\n",
    "    num_neurons: num_actions\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коэффициент скорости обучения\n",
    "Большие значения (0,7 – 1) будут соответствовать большому значению шага коррекции. При этом алгоритм будет работать быстрее (т.е. для поиска минимума функции ошибки потребуется меньше шагов), однако может снизиться точность настройки на минимум, что потенциально увеличит ошибку обучения. Малые значения коэффициента (0,1 – 0,3) соответствуют меньшему шагу коррекции весов. При этом число шагов (или эпох), требуемое для поиска оптимума, как правило, увеличивается, но возрастает и точность настройки на минимум, что потенциально уменьшает ошибку обучения. На практике коэффициент скорости обучения обычно подбирают экспериментально.\n",
    "\n",
    "```\n",
    "var tdtrainer_options = {\n",
    "    // Коэффициент скорости обучения\n",
    "    learning_rate: 0.001,\n",
    "    \n",
    "    // Количество объектов, которые мы передаём за 1 итерацию обучения\n",
    "    batch_size: 64,\n",
    "    l2_decay: 0.01,\n",
    "    momentum: 0.0,\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "// Объект в котором будем хранить настройки\n",
    "var opt = {};\n",
    "\n",
    "// Описывалось выше\n",
    "opt.temporal_window = temporal_window;\n",
    "\n",
    "// size of experience replay memory\n",
    "opt.experience_size = 3000;\n",
    "\n",
    "// number of examples in experience replay memory before we begin learning\n",
    "opt.start_learn_threshold = 500;\n",
    "\n",
    "// gamma is a crucial parameter that controls how much plan-ahead the agent does. In [0,1]\n",
    "opt.gamma = 0.7;\n",
    "\n",
    "// number of steps we will learn for\n",
    "opt.learning_steps_total = 10000;\n",
    "\n",
    "// how many steps of the above to perform only random actions (in the beginning)?\n",
    "opt.learning_steps_burnin = 1000;\n",
    "\n",
    "// what epsilon value do we bottom out on? 0.0 => purely deterministic policy at end\n",
    "opt.epsilon_min = 0.0;\n",
    "\n",
    "// what epsilon to use at test time? (i.e. when learning is disabled)\n",
    "opt.epsilon_test_time = 0.0;\n",
    "\n",
    "// Наши слои\n",
    "opt.layer_defs = layer_defs;\n",
    "\n",
    "// Настройки нейронки\n",
    "opt.tdtrainer_options = tdtrainer_options;\n",
    "\n",
    "// Чёрная коробка\n",
    "brain = new deepqlearn.Brain(num_inputs, num_actions, opt);\n",
    "```\n",
    "\n",
    "# И наконец - последняя функция которая делает магию\n",
    "![](http://s9.pikabu.ru/post_img/2016/12/12/8/og_og_1481547098267285367.jpg)\n",
    "\n",
    "```\n",
    "// Функция, которая вызывается при обучении\n",
    "learn = function (state, lastReward) {\n",
    "    // Тут происходит вся магия\n",
    "    brain.backward(lastReward);\n",
    "    \n",
    "    // Получаем action\n",
    "    var action = brain.forward(state);\n",
    "       \n",
    "    // Функции которые рисуют статистику\n",
    "    draw_net();\n",
    "    draw_stats();\n",
    "       \n",
    "    // Возвращаем action\n",
    "    return action;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код\n",
    "### Скопируй и вставь\n",
    "```\n",
    "lanesSide = 0; // Количество лийи вокруг *радиус*\n",
    "patchesAhead = 1; // Количество клеток впереди\n",
    "patchesBehind = 0; // Количество клеток позади\n",
    "\n",
    "// Количество итераций при нажатии кнопки начать обучение\n",
    "trainIterations = 10000; \n",
    "\n",
    "// (Количество линий * 2 (справа и слева) + 1 (по середине)) * (количество клеток впереди + количество клето позади)\n",
    "var num_inputs = (lanesSide * 2 + 1) * (patchesAhead + patchesBehind);\n",
    "\n",
    "// Бездействовать = 0;\n",
    "// Ускорится = 1;\n",
    "// Замедлиться = 2;\n",
    "// Повернуть налево = 3;\n",
    "// Повернуть направо = 4;\n",
    "\n",
    "// Количество действи\n",
    "var num_actions = 5;\n",
    "\n",
    "// Количество раз которое мы запоминаем\n",
    "var temporal_window = 3;\n",
    "\n",
    "// Количество нейронов на вход\n",
    "var network_size = num_inputs * temporal_window + num_actions * temporal_window + num_inputs;\n",
    "\n",
    "// Массив со слоями нейронной сети\n",
    "var layer_defs = [];\n",
    "\n",
    "// Входной слой\n",
    "layer_defs.push({\n",
    "    type: 'input',\n",
    "    out_sx: 1,\n",
    "    out_sy: 1,\n",
    "    out_depth: network_size\n",
    "});\n",
    "\n",
    "// FC (i.e. fully-connected)\n",
    "layer_defs.push({\n",
    "    type: 'fc',\n",
    "    num_neurons: 1,\n",
    "    activation: 'relu'\n",
    "});\n",
    "\n",
    "// Выходной слой, который предсказывает вероятности \n",
    "layer_defs.push({\n",
    "    type: 'regression',\n",
    "    num_neurons: num_actions\n",
    "});\n",
    "\n",
    "var tdtrainer_options = {\n",
    "    // Коэффициент скорости обучения\n",
    "    learning_rate: 0.001,\n",
    "\n",
    "    // Количество объектов, которые мы передаём за 1 итерацию обучения\n",
    "    batch_size: 64,\n",
    "\n",
    "    l2_decay: 0.01,\n",
    "    momentum: 0.0,\n",
    "};\n",
    "\n",
    "// Объект в котором будем хранить настройки\n",
    "var opt = {};\n",
    "\n",
    "// Описывалось выше\n",
    "opt.temporal_window = temporal_window;\n",
    "\n",
    "// size of experience replay memory\n",
    "opt.experience_size = 3000;\n",
    "\n",
    "// number of examples in experience replay memory before we begin learning\n",
    "opt.start_learn_threshold = 500;\n",
    "\n",
    "// gamma is a crucial parameter that controls how much plan-ahead the agent does. In [0,1]\n",
    "opt.gamma = 0.7;\n",
    "\n",
    "// number of steps we will learn for\n",
    "opt.learning_steps_total = 10000;\n",
    "\n",
    "// how many steps of the above to perform only random actions (in the beginning)?\n",
    "opt.learning_steps_burnin = 1000;\n",
    "\n",
    "// what epsilon value do we bottom out on? 0.0 => purely deterministic policy at end\n",
    "opt.epsilon_min = 0.0;\n",
    "\n",
    "// what epsilon to use at test time? (i.e. when learning is disabled)\n",
    "opt.epsilon_test_time = 0.0;\n",
    "\n",
    "// Наши слои\n",
    "opt.layer_defs = layer_defs;\n",
    "\n",
    "// Настройки нейронки\n",
    "opt.tdtrainer_options = tdtrainer_options;\n",
    "\n",
    "// Чёрная коробка\n",
    "brain = new deepqlearn.Brain(num_inputs, num_actions, opt);\n",
    "\n",
    "// Функция, которая вызывается при обучении\n",
    "learn = function (state, lastReward) {\n",
    "    // Тут происходит вся магия\n",
    "    brain.backward(lastReward);\n",
    "\n",
    "    // Получаем action\n",
    "    var action = brain.forward(state);\n",
    "\n",
    "    // Функции которые рисуют статистику\n",
    "    draw_net();\n",
    "    draw_stats();\n",
    "\n",
    "    // Возвращаем action\n",
    "    return action;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ура!\n",
    "\n",
    "## Что делать дальше?\n",
    "1. Можно посмотреть в эти же тетрадки дома и разобраться более детально. [Вот](https://github.com/tvorogme/digitalfest) репозиторий!\n",
    "2. Прочитай [блог школы GoTo](https://habrahabr.ru/company/goto/blog/339050/), рассказывающий, с чего начинать изучать анализ данных и машинное обучение.\n",
    "3. Когда ты наберёшься знаний и тебе захочется проверить свои силы, попробуй поучаствовать в соревнованиях на [kaggle](https://www.kaggle.com/competitions)\n",
    "\n",
    "4. Когда ты научишься самостоятельно обучать нейронные сети, CPU для вычислений начнёт не хватать. Подумай о покупке GPU. Подойдёт любая CUDA-совместимая видеокарта, но чем мощнее - тем лучше\n",
    "<br><br>\n",
    "![](screens/zmubBCUZwBg.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
